# CNN Model EÄŸitimi - Trafik Ä°ÅŸaretleri
# Ã–nceki data_analysis.py'dan sonra Ã§alÄ±ÅŸtÄ±rÄ±n

import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import cv2
import os
from datetime import datetime

# Veri setinin bulunduÄŸu klasÃ¶r
DATA_PATH = "Trafic Signs Preprocssed data/"

def load_preprocessed_data():
    """Ã–nceden iÅŸlenmiÅŸ veri setini yÃ¼kler"""
    print("Veri yÃ¼kleniyor...")
    
    # EÄŸitim verisi
    with open(DATA_PATH + "train.pickle", "rb") as f:
        train_data = pickle.load(f)
    X_train = train_data['features']
    y_train = train_data['labels']
    
    # DoÄŸrulama verisi  
    with open(DATA_PATH + "valid.pickle", "rb") as f:
        valid_data = pickle.load(f)
    X_valid = valid_data['features']
    y_valid = valid_data['labels']
    
    # Test verisi
    with open(DATA_PATH + "test.pickle", "rb") as f:
        test_data = pickle.load(f)
    X_test = test_data['features']
    y_test = test_data['labels']
    
    print(f"âœ… EÄŸitim verisi: {X_train.shape}")
    print(f"âœ… DoÄŸrulama verisi: {X_valid.shape}")
    print(f"âœ… Test verisi: {X_test.shape}")
    
    return X_train, y_train, X_valid, y_valid, X_test, y_test

def normalize_data(X_train, X_valid, X_test):
    """Veriyi normalize et (0-1 arasÄ±na getir)"""
    print("Veri normalize ediliyor...")
    
    if X_train.max() > 1:
        X_train_norm = X_train.astype('float32') / 255.0
        X_valid_norm = X_valid.astype('float32') / 255.0
        X_test_norm = X_test.astype('float32') / 255.0
        print(f"âœ… Normalizasyon tamamlandÄ±: {X_train_norm.min():.3f} - {X_train_norm.max():.3f}")
    else:
        X_train_norm = X_train.astype('float32')
        X_valid_norm = X_valid.astype('float32')
        X_test_norm = X_test.astype('float32')
        print("âœ… Veri zaten normalize edilmiÅŸ")
    
    return X_train_norm, X_valid_norm, X_test_norm

def create_data_augmentation():
    """Veri artÄ±rma katmanlarÄ±"""
    data_augmentation = keras.Sequential([
        layers.RandomRotation(0.1),                    # Â±10 derece dÃ¶ndÃ¼rme
        layers.RandomZoom(0.1),                        # %10 zoom
        layers.RandomBrightness(0.1),                  # ParlaklÄ±k deÄŸiÅŸimi
        layers.RandomContrast(0.1),                    # Kontrast deÄŸiÅŸimi
    ])
    return data_augmentation

def create_cnn_model_v1(input_shape=(32, 32, 3), num_classes=43):
    """Basit CNN modeli (Versiyon 1)"""
    print("ğŸ”¨ Basit CNN modeli oluÅŸturuluyor...")
    
    model = keras.Sequential([
        # GiriÅŸ katmanÄ±
        layers.Input(shape=input_shape),
        
        # Ä°lk konvolÃ¼syon bloÄŸu
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Ä°kinci konvolÃ¼syon bloÄŸu
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # ÃœÃ§Ã¼ncÃ¼ konvolÃ¼syon bloÄŸu
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Dropout(0.25),
        
        # Classifier
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

def create_cnn_model_v2(input_shape=(32, 32, 3), num_classes=43):
    """GeliÅŸmiÅŸ CNN modeli (Versiyon 2) - Veri artÄ±rma ve Batch Normalization ile"""
    print("ğŸš€ GeliÅŸmiÅŸ CNN modeli oluÅŸturuluyor...")
    
    # Veri artÄ±rma
    data_augmentation = create_data_augmentation()
    
    model = keras.Sequential([
        # Veri artÄ±rma (sadece eÄŸitimde aktif)
        data_augmentation,
        
        # Ä°lk blok
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Ä°kinci blok
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # ÃœÃ§Ã¼ncÃ¼ blok
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.25),
        
        # Global Average Pooling (Flatten yerine)
        layers.GlobalAveragePooling2D(),
        
        # Classifier
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

def compile_model(model, learning_rate=0.001): #LR ayarÄ±nÄ± ekledik ORT, daha kÃ¼Ã§Ã¼k veya bÃ¼yÃ¼k olabilir
    """Modeli derle"""
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("âœ… Model derlendi")
    return model

def setup_callbacks(model_name="traffic_sign_model"):
    """EÄŸitim callback'lerini ayarla"""
    callbacks = [
        # Erken durma - 5 epoch boyunca iyileÅŸme yoksa dur
        EarlyStopping(
            monitor='val_accuracy',
            patience=7,
            restore_best_weights=True,
            verbose=1
        ),
        
        # Learning rate azaltma - 3 epoch boyunca iyileÅŸme yoksa LR'yi azalt
        ReduceLROnPlateau(
            monitor='val_accuracy',
            factor=0.5,
            patience=3,
            min_lr=0.00001,
            verbose=1
        ),
        
        # En iyi modeli kaydet    # .h5 yerine Keras'Ä±n yeni formatÄ± olan .keras kullanabilirsiniz?
        ModelCheckpoint(
            f"{model_name}_best.keras" ,  # .h5 yerine .keras
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    return callbacks

def train_model(model, X_train, y_train, X_valid, y_valid, epochs=30, batch_size=32):
    """Modeli eÄŸit"""
    print(f"ğŸ‹ï¸â€â™‚ï¸ Model eÄŸitimi baÅŸlÄ±yor... ({epochs} epoch)")
    
    # Callback'leri ayarla      #OlasÄ± sorun 2. model iÃ§in .h5 yerine .keras kullanÄ±lmasÄ± olabilir?? araÅŸtÄ±r
    callbacks = setup_callbacks()
    
    # EÄŸitimi baÅŸlat
    start_time = datetime.now()
    
    history = model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(X_valid, y_valid),
        callbacks=callbacks,
        verbose=1
    )
    
    end_time = datetime.now()
    training_time = end_time - start_time
    
    print(f"âœ… EÄŸitim tamamlandÄ±! SÃ¼re: {training_time}")
    
    return history

def plot_training_history(history):
    """EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Accuracy grafiÄŸi
    ax1.plot(history.history['accuracy'], label='EÄŸitim DoÄŸruluÄŸu', marker='o')
    ax1.plot(history.history['val_accuracy'], label='DoÄŸrulama DoÄŸruluÄŸu', marker='s')
    ax1.set_title('Model DoÄŸruluÄŸu')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Loss grafiÄŸi
    ax2.plot(history.history['loss'], label='EÄŸitim Loss', marker='o')
    ax2.plot(history.history['val_loss'], label='DoÄŸrulama Loss', marker='s')
    ax2.set_title('Model Loss')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # En iyi sonuÃ§larÄ± yazdÄ±r
    best_train_acc = max(history.history['accuracy'])
    best_val_acc = max(history.history['val_accuracy'])
    
    print(f"\nğŸ“Š EÄÄ°TÄ°M SONUÃ‡LARI:")
    print(f"En iyi eÄŸitim doÄŸruluÄŸu: {best_train_acc:.4f}")
    print(f"En iyi doÄŸrulama doÄŸruluÄŸu: {best_val_acc:.4f}")
    
    return best_val_acc

def evaluate_model(model, X_test, y_test):
    """Modeli test verisiyle deÄŸerlendir"""
    print("\nğŸ§ª Model test ediliyor...")
    
    # Test doÄŸruluÄŸu
    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
    
    print(f"ğŸ“ˆ TEST SONUÃ‡LARI:")
    print(f"Test Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    
    return test_accuracy

# Ana eÄŸitim fonksiyonu
def main_training():
    """Ana eÄŸitim pipeline'Ä±"""
    print("=" * 60)
    print("ğŸš¦ TRAFÄ°K Ä°ÅARETÄ° CNN MODEL EÄÄ°TÄ°MÄ°")
    print("=" * 60)
    
    # 1. Veriyi yÃ¼kle
    X_train, y_train, X_valid, y_valid, X_test, y_test = load_preprocessed_data() 
    
    # 2. Normalize et
    X_train_norm, X_valid_norm, X_test_norm = normalize_data(X_train, X_valid, X_test)
    
    print(f"\nğŸ“Š VERÄ° BÄ°LGÄ°LERÄ°:")
    print(f"GÃ¶rÃ¼ntÃ¼ boyutu: {X_train_norm.shape[1:]}")
    print(f"SÄ±nÄ±f sayÄ±sÄ±: {len(np.unique(y_train))}")
    print(f"EÄŸitim Ã¶rnekleri: {len(X_train_norm):,}")
    print(f"DoÄŸrulama Ã¶rnekleri: {len(X_valid_norm):,}")
    print(f"Test Ã¶rnekleri: {len(X_test_norm):,}")
    
    # 3. Model seÃ§ (1 veya 2)
    print("\nğŸ”§ MODEL SEÃ‡Ä°MÄ°:")
    print("1ï¸âƒ£  Basit CNN (HÄ±zlÄ± eÄŸitim)")
    print("2ï¸âƒ£  GeliÅŸmiÅŸ CNN (Daha iyi performans)")
    
    choice = input("Hangi modeli kullanmak istiyorsunuz? (1/2): ")
    
    if choice == "1":
        model = create_cnn_model_v1()
        model_name = "basit_cnn"
        epochs = 20
    else:
        model = create_cnn_model_v2()
        model_name = "gelismis_cnn"
        epochs = 30
    
    # 4. Modeli derle
    model = compile_model(model)
    
    # 5. Model Ã¶zetini gÃ¶ster
    print(f"\nğŸ—ï¸  {model_name.upper()} MODEL Ã–ZETÄ°:")
    model.summary()
    
    # 6. Modeli eÄŸit
    history = train_model(model, X_train_norm, y_train, X_valid_norm, y_valid, epochs=epochs)
    
    # 7. SonuÃ§larÄ± gÃ¶rselleÅŸtir
    best_val_acc = plot_training_history(history)
    
    # 8. Test et
    test_accuracy = evaluate_model(model, X_test_norm, y_test)
    
    # 9. Modeli kaydet
    model_filename = f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M')}.keras"
    model.save(model_filename)
    print(f"\nğŸ’¾ Model kaydedildi: {model_filename}")
    
    print(f"\nğŸ‰ EÄÄ°TÄ°M TAMAMLANDI!")
    print(f"DoÄŸrulama DoÄŸruluÄŸu: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)")
    print(f"Test DoÄŸruluÄŸu: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    
    return model, history

if __name__ == "__main__":
    # EÄŸitimi baÅŸlat
    model, history = main_training()